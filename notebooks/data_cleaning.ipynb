from nbformat import v4 as nbf

# Define notebook cells
cells = []

# Title markdown
cells.append(nbf.new_markdown_cell("# ðŸ§¹ Data Cleaning Notebook for Titanic Dataset"))

# Import libraries
cells.append(nbf.new_code_cell("""
# 1. Import libraries
import pandas as pd
import numpy as np
import re
"""))

# Load raw dataset and exploratory checks
cells.append(nbf.new_code_cell("""
# 2. Load raw dataset
df = pd.read_csv("../data/raw_dataset.csv")

# Exploratory checks
print("=== Dataset Info ===")
df.info()

print("\\n=== Dataset Description ===")
print(df.describe(include="all"))

# Missing values
print("\\n=== Missing Values Per Column ===")
print(df.isnull().sum())

# Duplicates check
duplicates = df.duplicated().sum()
print(f"\\n=== Duplicate Rows Found: {duplicates} ===")
"""))

# Cleaning steps
cells.append(nbf.new_code_cell("""
# ================================================================
# 4. Handle Missing Values
# ================================================================

# Age â†’ fill missing with median, convert to int
df['Age'] = df['Age'].fillna(df['Age'].median()).astype(int)

# Embarked â†’ fill missing with most common (mode)
df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])

# Cabin â†’ replace NaN with 'Unknown'
df['Cabin'] = df['Cabin'].fillna('Unknown')

# Drop rows that are entirely empty
df = df.dropna(how="all")
"""))

cells.append(nbf.new_code_cell("""
# ================================================================
# 5. Clean Name Column
# ================================================================

# Remove titles (Mr., Mrs., Miss., Master., Dr., etc.)
df['Name'] = df['Name'].str.replace(r"(Mr\\.|Mrs\\.|Miss\\.|Master\\.|Don\\.|Dr\\.|Rev\\.)", "", regex=True)

# Remove parentheses and contents inside them
df['Name'] = df['Name'].str.replace(r"\\(.*\\)", "", regex=True).str.strip()

# Split Surname, Firstname -> reorder to Firstname Surname
def reorder_name(name):
    if "," in name:
        parts = [p.strip() for p in name.split(",")]
        if len(parts) >= 2:
            return parts[1] + " " + parts[0]
    return name

df['Name'] = df['Name'].apply(reorder_name)
"""))

cells.append(nbf.new_code_cell("""
# ================================================================
# 6. Ticket Column Cleaning
# ================================================================

# Extract numeric part of ticket (remove letters, spaces, dots)
df['Ticket'] = df['Ticket'].astype(str).str.replace(r"\\D", "", regex=True)

# Drop duplicates based on Ticket Number
df = df.drop_duplicates(subset=['Ticket'])

# Ensure Ticket column is numeric
df['Ticket'] = pd.to_numeric(df['Ticket'], errors='coerce')
"""))

cells.append(nbf.new_code_cell("""
# ================================================================
# 7. Standardize Sex Column
# ================================================================

df['Sex'] = df['Sex'].str.strip().str.lower()
"""))

cells.append(nbf.new_code_cell("""
# ================================================================
# 8. Fare Column
# ================================================================

# Fill missing fares with median
df['Fare'] = df['Fare'].fillna(df['Fare'].median())

# Round to 2 decimal places
df['Fare'] = df['Fare'].round(2)
"""))

cells.append(nbf.new_code_cell("""
# ================================================================
# 9. Cabin Column
# ================================================================

# Keep only the first letter (deck)
df['Cabin'] = df['Cabin'].apply(lambda x: x[0] if x != 'Unknown' else 'Unknown')
"""))

cells.append(nbf.new_code_cell("""
# ================================================================
# 10. Remove Duplicate Rows
# ================================================================

df = df.drop_duplicates()

print("Cleaned Shape:", df.shape)
"""))

cells.append(nbf.new_code_cell("""
# ================================================================
# 11. Save Cleaned Dataset
# ================================================================
df.to_csv("../data/cleaned_dataset.csv", index=False)
print("âœ… Cleaned dataset saved!")
"""))

# Create notebook object
nb = nbf.new_notebook(cells=cells)

# Save notebook file
notebook_path = "/mnt/data/data_cleaning.ipynb"
with open(notebook_path, "w", encoding="utf-8") as f:
    import json
    json.dump(nb, f)

notebook_path