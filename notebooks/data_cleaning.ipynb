{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ðŸ§¹ Titanic Dataset Data Cleaning Script\n",
    "Author: Jemar John J. Lumingkit\n",
    "Description: Loads Titanic dataset, performs cleaning, and saves cleaned version.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a021cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Dataset\n",
    "print(\"=== Loading Dataset ===\")\n",
    "df = pd.read_csv(\"../data/raw_dataset.csv\")\n",
    "print(\"Original Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca7317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initial Exploration\n",
    "print(\"\\n=== Dataset Info ===\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b48d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Dataset Description ===\")\n",
    "print(df.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbdfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Missing Values Per Column ===\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2de574",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\n=== Duplicate Rows Found: {duplicates} ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 4. Handle Missing Values\n",
    "# ================================================================\n",
    "print(\"\\n=== Handling Missing Values ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e64ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age â†’ fill missing with median, convert to int\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14198a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked â†’ fill missing with most common (mode)\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1453e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabin â†’ replace NaN with 'Unknown'\n",
    "df['Cabin'] = df['Cabin'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that are entirely empty\n",
    "df = df.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10618ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 5. Clean Name Column\n",
    "# ================================================================\n",
    "print(\"\\n=== Cleaning Name Column ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove titles (Mr., Mrs., Miss., Master., Don., Dr., Rev., etc.)\n",
    "df['Name'] = df['Name'].str.replace(\n",
    "    r\"(Mr\\.|Mrs\\.|Miss\\.|Master\\.|Don\\.|Dr\\.|Rev\\.)\", \"\", regex=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89da195",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Remove parentheses and contents inside them\n",
    "df['Name'] = df['Name'].str.replace(r\"\\(.*\\)\", \"\", regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99748f8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Reorder names: \"Surname, Firstname\" â†’ \"Firstname Surname\"\n",
    "def reorder_name(name):\n",
    "    if \",\" in name:\n",
    "        parts = [p.strip() for p in name.split(\",\")]\n",
    "        if len(parts) >= 2:\n",
    "            return parts[1] + \" \" + parts[0]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name'] = df['Name'].apply(reorder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 6. Ticket Column Cleaning\n",
    "# ================================================================\n",
    "print(\"\\n=== Cleaning Ticket Column ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa859f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric part of ticket (remove letters, spaces, dots)\n",
    "df['Ticket'] = df['Ticket'].astype(str).str.replace(r\"\\D\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bfaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on Ticket Number\n",
    "df = df.drop_duplicates(subset=['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Ticket column is numeric\n",
    "df['Ticket'] = pd.to_numeric(df['Ticket'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 7. Standardize Sex Column\n",
    "# ================================================================\n",
    "df['Sex'] = df['Sex'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 8. Fare Column\n",
    "# ================================================================\n",
    "print(\"\\n=== Cleaning Fare Column ===\")\n",
    "df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "df['Fare'] = df['Fare'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb731b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 9. Cabin Column\n",
    "# ================================================================\n",
    "print(\"\\n=== Simplifying Cabin Column ===\")\n",
    "df['Cabin'] = df['Cabin'].apply(lambda x: x[0] if x != 'Unknown' else 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be57b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 10. Remove Duplicate Rows\n",
    "# ================================================================\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e021829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 11. Save Cleaned Dataset\n",
    "# ================================================================\n",
    "print(\"\\n=== Saving Cleaned Dataset ===\")\n",
    "print(\"Cleaned Shape:\", df.shape)\n",
    "df.to_csv(\"../data/cleaned_dataset.csv\", index=False)\n",
    "print(\"âœ… Cleaned dataset saved at ../data/cleaned_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
